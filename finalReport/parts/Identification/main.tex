%\part{System Identification and Filtering}
\chapter{Identification introduction}
The system considered can be easily modelled and identified without the need to use black-box identification to identify the system. \\ For completeness both \emph{white-box} and \emph{grey-box} identification are used.\\ \\
First of all the problem of whether to consider a \emph{closed} or \emph{open} loop system is considered. In fact \emph{back-emf} can be seen as a gain acting on the velocity of the cart, thus it's a gain on the closed loop.\\ \\
Then, using both \emph{white-box} and \emph{grey-box} identification we identified the main parameters of the system: 
\begin{enumerate}
\item Resistance and inductance for the motor.
\item Mass, stiffness and damping for the cart and the springs.
\end{enumerate}
Last, identification of non-linearities are considered.
\section{Validation cost function}
\label{sec:validation_cost_function}
An important aspect of the identification process is validation of results and this can be done in many ways. \\ \\
We will mainly compare two signals, thus effectiveness in capturing the shape of  a signal is essential for the type of validation function that we will use. \\  \\
For this purpose we can make use of a distance function $d(x,y): \mathbb{R}^n \times \mathbb{R}^n\to [0,1]$ induced by a generic norm $n(x) : \mathbb{R}^n \to [0,\infty)$. In this case we can construct $d$ in the following way:
\begin{equation}d(x,y) = \frac{1}{1+n(x-y)}\end{equation}
 The problem, then, is to find a norm capable of capturing the essential information of a signal. \\ \\Usually the $L_2$ norm is used, since it's related to the signal energy, and from a statistical point of view it corresponds to the variance of the difference of two signals. It's called \emph{MSE}-\emph{Mean Square Error}: an estimator of the overall deviations between prediction and measurements. Mathematically:
\begin{equation}\text{MSE} =  \mathbb{E}[(x-y)^2]\end{equation}
Where $n$ is the dimension of $x,y$.

Why does it corresponds to the $L_2$ norm? First of all, notice that $\mathbb{E}[vw]$, where $v,w$ are random variables, corresponds to a non-scaled projection of $v$ on $w$. Any projection can be written in terms of a generic scalar product $<\cdot,\cdot>$, because of the Projection Theorem,  thus:
\begin{equation}\mathbb{E}[(v-w)^2] = <v-w,v-w>\end{equation}
The last term corresponds to the square of a norm $||v-w||^2$, which can be proven to be the $L_2$ norm:
\begin{equation}\mathbb{E}[(v-w)^2]  = \frac{1}{T} \int_0^T (v-w)^2 dt = \frac{1}{T} ||v-w||_2^2 \end{equation}
But does the $L_2$ norm capture information about the shape of a signal? For signals with finite energy the $L_2$ norm in time corresponds to a $L_2$ norm in frequency, due to the Parseval's Theorem. Therefore minimizing the $L_2$ norm implies the minimization of shape differences between the two signals.
\\ \\
Therefore, \emph{MSE} as defined before, is the square of a norm. Thus:
\begin{equation}n(z) = \sqrt{\mathbb{E}[z^2]}\end{equation}
is a norm.
And the validation cost function is:
\begin{equation}d(x,y)= \frac{1}{1+n(x-y)}=\ \frac{1}{1+\sqrt{\mathbb{E}[(x-y)^2]}}\end{equation}
%This is a type of absolute error, whilst during the course of the project the relative error between a reference signal $x$ and a signal $y$ was calculated as:
%$$r=\frac{||x-y||_{\infty}}{||x||_{\infty}}$$
\subimport{common}{ol_vs_cl_identification}
\subimport{common}{white_box_identification}
\subimport{common}{gray_box_identification}
\subimport{common}{non_linearities_identification}
\subimport{common}{filtering}